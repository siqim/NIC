# -*- coding: utf-8 -*-
"""
Created in Oct 2018

"""

import os
import time
import pickle
import numpy as np

import torch
import torch.nn as nn
import torch.nn.utils.rnn as rnn_utils
import torch.optim as optim
from torchvision import transforms

from models import CNN, RNN
from utils import save_model, load_model, decode_idx2word
from dataloader import MSCOCO, collate_fn


#DEBUG = True
DEBUG = False

NO_WORD_EMBEDDINGS = 300
VOCAB_SIZE = 17000
HIDDEN_SIZE = 512
BATCH_SIZE = 32
NUM_LAYERS = 1
EPOCHS = 500
LR = 0.0001
NUM_WORKERS = 0
#MOMENTUM = 0.9 # if SGD
current_epoch = 1
time_used_global = 0.0
checkpoint = 5

model_dir = '../saved_model/'
train_imagepaths_and_captions = '../preprocessed_data/imagepaths_captions.train'
val_imagepaths_and_captions = '../preprocessed_data/imagepaths_captions.val'
pretrained_resnet101_file = '../pre_trained/resnet101-5d3b4d8f.pth'
pretrained_word_embeddings_file = '../preprocessed_data/embeddings'
id2word = np.array(pickle.load(open('../preprocessed_data/idx2word', 'rb'))) # used to decode the result generated by decoder.


transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ColorJitter(
            brightness=0.1*torch.randn(1),
            contrast=0.1*torch.randn(1),
            saturation=0.1*torch.randn(1),
            hue=0.1*torch.randn(1)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.4701, 0.4469, 0.4076], [0.2692, 0.2646, 0.2801])
])

transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.4701, 0.4469, 0.4076], [0.2692, 0.2646, 0.2801])
])

print('Loading dataset...')
trainset = MSCOCO(train_imagepaths_and_captions, transform_train)
trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True, num_workers=NUM_WORKERS)

valset = MSCOCO(val_imagepaths_and_captions, transform_val)
valloader = torch.utils.data.DataLoader(dataset=valset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True, num_workers=NUM_WORKERS)

print('Initializing models...')
encoder = CNN(BATCH_SIZE, NO_WORD_EMBEDDINGS, pretrained_resnet101_file, freeze=True)
decoder = RNN(BATCH_SIZE, VOCAB_SIZE, NO_WORD_EMBEDDINGS, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS,
              pre_trained_file=pretrained_word_embeddings_file, freeze=False)
encoder.cuda()
decoder.cuda()

model_paras = list(encoder.parameters()) + list(decoder.parameters())
#optimizer = optim.SGD(model_paras, lr=LR, momentum=MOMENTUM)
optimizer = optim.Adam(model_paras, lr=LR)


# load lastest model to resume training
model_list = os.listdir(model_dir)
if model_list:
    state = load_model(model_dir, model_list)
    encoder.load_state_dict(state['encoder'])
    decoder.load_state_dict(state['decoder'])
    optimizer.load_state_dict(state['optimizer'])
    current_epoch = state['epoch'] + 1
    time_used_global = state['time_used_global']

criterion = nn.CrossEntropyLoss()

for epoch in range(current_epoch, EPOCHS+1):
    start_time_epoch = time.time()
    encoder.train()
    decoder.train()
    
    print('Start training...')
    for batch_idx, (images, captions, lengths) in enumerate(trainloader, 1):
        
        images = images.cuda()
        captions = captions.cuda()
        lengths = lengths.cuda()
        targets = rnn_utils.pack_padded_sequence(captions, lengths, batch_first=True)[0]
        
        encoder.zero_grad()
        decoder.zero_grad()
        
        image_embeddings = encoder(images)
        generated_captions = decoder(image_embeddings, captions, lengths)

        loss = criterion(generated_captions, targets)
        
        loss.backward()
        optimizer.step()
        
        if batch_idx % 100 == 0:
            print('[%d] batch, [%.4f] loss, [%.2f] min used.'%(batch_idx, loss, (time.time()-start_time_epoch)/60))

        if DEBUG:
            break
        
        
    time_used_epoch = time.time() - start_time_epoch
    time_used_global += time_used_epoch
    
    if epoch % checkpoint == 0:
        save_model(epoch, time_used_global, optimizer, encoder, decoder)

    if DEBUG:
        break        
